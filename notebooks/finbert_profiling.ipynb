{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FinBERT Profiling Notebook\n",
        "\n",
        "This notebook profiles the FinBERT training and inference process to establish performance baselines. It uses PyTorch Profiler to analyze:\n",
        "- Data loading time\n",
        "- Forward pass time\n",
        "- Backward pass time\n",
        "- Optimizer step time\n",
        "- Inference time\n",
        "\n",
        "This serves as a benchmark before optimization.\n",
        "\n",
        "**Note on Device Support:**\n",
        "- **CUDA (NVIDIA GPUs)**: Full profiling support with separate CPU and CUDA time tracking\n",
        "- **MPS (Apple Silicon)**: Only CPU time profiling available. While computation runs on GPU, PyTorch Profiler cannot separately track MPS GPU time\n",
        "- **CPU**: Standard CPU time profiling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/taimurshaikh/Desktop/Coding/Classwork/HPML/finBERT/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from textblob import TextBlob\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from finbert.finbert import *\n",
        "import finbert.utils as tools\n",
        "\n",
        "import torch\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "project_dir = Path.cwd().parent\n",
        "pd.set_option('max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Profiled FinBERT Class\n",
        "\n",
        "This class extends the base FinBERT class to add profiling instrumentation to the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ProfiledFinBert(FinBert):\n",
        "    \"\"\"Extended FinBert class with profiling instrumentation.\n",
        "    \n",
        "    Note: GPU-specific profiling (ProfilerActivity.CUDA) only works with NVIDIA CUDA devices.\n",
        "    For MPS (Apple Silicon), only CPU profiling is available, though actual computation runs on GPU.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.profile_results = {}\n",
        "    \n",
        "    def train(self, train_examples, model):\n",
        "        \"\"\"\n",
        "        Trains the model with profiling instrumentation.\n",
        "        \"\"\"\n",
        "        validation_examples = self.get_data('validation')\n",
        "        global_step = 0\n",
        "        self.validation_losses = []\n",
        "        \n",
        "        # Training\n",
        "        train_dataloader = self.get_loader(train_examples, 'train')\n",
        "        model.train()\n",
        "        step_number = len(train_dataloader)\n",
        "        \n",
        "        # Setup profiler - CUDA profiling only works with NVIDIA GPUs, not MPS\n",
        "        activities = [ProfilerActivity.CPU]\n",
        "        if self.device.type == \"cuda\":\n",
        "            activities.append(ProfilerActivity.CUDA)\n",
        "        \n",
        "        print(\"\\\\n\" + \"=\"*80)\n",
        "        print(\"Starting Profiled Training\")\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(f\"Profiling activities: {activities}\")\n",
        "        if self.device.type == \"mps\":\n",
        "            print(\"Note: MPS profiling shows CPU time only. Actual GPU execution time not separately tracked.\")\n",
        "        print(\"=\"*80 + \"\\\\n\")\n",
        "        \n",
        "        i = 0\n",
        "        \n",
        "        with profile(\n",
        "            activities=activities,\n",
        "            record_shapes=True,\n",
        "            profile_memory=True,\n",
        "            with_stack=False\n",
        "        ) as prof:\n",
        "            \n",
        "            for epoch in trange(int(self.config.num_train_epochs), desc=\"Epoch\"):\n",
        "                model.train()\n",
        "                tr_loss = 0\n",
        "                nb_tr_examples, nb_tr_steps = 0, 0\n",
        "                \n",
        "                for step, batch in enumerate(tqdm(train_dataloader, desc='Iteration')):\n",
        "                    \n",
        "                    # Gradual unfreezing logic\n",
        "                    if (self.config.gradual_unfreeze and i == 0):\n",
        "                        for param in model.bert.parameters():\n",
        "                            param.requires_grad = False\n",
        "                    \n",
        "                    if (step % (step_number // 3)) == 0:\n",
        "                        i += 1\n",
        "                    \n",
        "                    if (self.config.gradual_unfreeze and i > 1 and i < self.config.encoder_no):\n",
        "                        for k in range(i - 1):\n",
        "                            try:\n",
        "                                for param in model.bert.encoder.layer[self.config.encoder_no - 1 - k].parameters():\n",
        "                                    param.requires_grad = True\n",
        "                            except:\n",
        "                                pass\n",
        "                    \n",
        "                    if (self.config.gradual_unfreeze and i > self.config.encoder_no + 1):\n",
        "                        for param in model.bert.embeddings.parameters():\n",
        "                            param.requires_grad = True\n",
        "                    \n",
        "                    # Data loading profiling\n",
        "                    with record_function(\"data_transfer\"):\n",
        "                        batch = tuple(t.to(self.device) for t in batch)\n",
        "                        input_ids, attention_mask, token_type_ids, label_ids, agree_ids = batch\n",
        "                    \n",
        "                    # Forward pass profiling\n",
        "                    with record_function(\"forward_pass\"):\n",
        "                        logits = model(input_ids, attention_mask, token_type_ids)[0]\n",
        "                    \n",
        "                    # Loss calculation profiling\n",
        "                    with record_function(\"loss_calculation\"):\n",
        "                        weights = self.class_weights.to(self.device)\n",
        "                        if self.config.output_mode == \"classification\":\n",
        "                            loss_fct = CrossEntropyLoss(weight=weights)\n",
        "                            loss = loss_fct(logits.view(-1, self.num_labels), label_ids.view(-1))\n",
        "                        elif self.config.output_mode == \"regression\":\n",
        "                            loss_fct = MSELoss()\n",
        "                            loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "                        \n",
        "                        if self.config.gradient_accumulation_steps > 1:\n",
        "                            loss = loss / self.config.gradient_accumulation_steps\n",
        "                    \n",
        "                    # Backward pass profiling\n",
        "                    with record_function(\"backward_pass\"):\n",
        "                        loss.backward()\n",
        "                    \n",
        "                    tr_loss += loss.item()\n",
        "                    nb_tr_examples += input_ids.size(0)\n",
        "                    nb_tr_steps += 1\n",
        "                    \n",
        "                    # Optimizer step profiling\n",
        "                    if (step + 1) % self.config.gradient_accumulation_steps == 0:\n",
        "                        with record_function(\"optimizer_step\"):\n",
        "                            if self.config.fp16:\n",
        "                                lr_this_step = self.config.learning_rate * warmup_linear(\n",
        "                                    global_step / self.num_train_optimization_steps, self.config.warm_up_proportion)\n",
        "                                for param_group in self.optimizer.param_groups:\n",
        "                                    param_group['lr'] = lr_this_step\n",
        "                            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                            self.optimizer.step()\n",
        "                            self.scheduler.step()\n",
        "                            self.optimizer.zero_grad()\n",
        "                            global_step += 1\n",
        "                    \n",
        "                    # Only profile first epoch to save time\n",
        "                    if epoch == 0 and step >= 20:\n",
        "                        break\n",
        "                \n",
        "                # Break after first epoch for profiling\n",
        "                if epoch == 0:\n",
        "                    print(\"\\\\n\" + \"=\"*80)\n",
        "                    print(\"Profiling complete for first epoch (20 steps)\")\n",
        "                    print(\"Continuing full training without profiling...\")\n",
        "                    print(\"=\"*80 + \"\\\\n\")\n",
        "                    break\n",
        "        \n",
        "        # Print profiler results\n",
        "        print(\"\\\\n\" + \"=\"*80)\n",
        "        print(\"PROFILING RESULTS - Training\")\n",
        "        print(\"=\"*80 + \"\\\\n\")\n",
        "        \n",
        "        print(\"\\\\nBy CPU Time:\")\n",
        "        print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "        \n",
        "        if self.device.type == \"cuda\":\n",
        "            print(\"\\\\nBy CUDA Time:\")\n",
        "            print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "        \n",
        "        print(\"\\\\n\" + \"=\"*80 + \"\\\\n\")\n",
        "        \n",
        "        # Store results\n",
        "        self.profile_results['training'] = prof.key_averages()\n",
        "        \n",
        "        # Continue with full training without profiling\n",
        "        for epoch in trange(int(self.config.num_train_epochs), desc=\"Epoch\"):\n",
        "            model.train()\n",
        "            tr_loss = 0\n",
        "            nb_tr_examples, nb_tr_steps = 0, 0\n",
        "            \n",
        "            for step, batch in enumerate(tqdm(train_dataloader, desc='Iteration')):\n",
        "                \n",
        "                if (self.config.gradual_unfreeze and i == 0):\n",
        "                    for param in model.bert.parameters():\n",
        "                        param.requires_grad = False\n",
        "                \n",
        "                if (step % (step_number // 3)) == 0:\n",
        "                    i += 1\n",
        "                \n",
        "                if (self.config.gradual_unfreeze and i > 1 and i < self.config.encoder_no):\n",
        "                    for k in range(i - 1):\n",
        "                        try:\n",
        "                            for param in model.bert.encoder.layer[self.config.encoder_no - 1 - k].parameters():\n",
        "                                param.requires_grad = True\n",
        "                        except:\n",
        "                            pass\n",
        "                \n",
        "                if (self.config.gradual_unfreeze and i > self.config.encoder_no + 1):\n",
        "                    for param in model.bert.embeddings.parameters():\n",
        "                        param.requires_grad = True\n",
        "                \n",
        "                batch = tuple(t.to(self.device) for t in batch)\n",
        "                input_ids, attention_mask, token_type_ids, label_ids, agree_ids = batch\n",
        "                \n",
        "                logits = model(input_ids, attention_mask, token_type_ids)[0]\n",
        "                weights = self.class_weights.to(self.device)\n",
        "                \n",
        "                if self.config.output_mode == \"classification\":\n",
        "                    loss_fct = CrossEntropyLoss(weight=weights)\n",
        "                    loss = loss_fct(logits.view(-1, self.num_labels), label_ids.view(-1))\n",
        "                elif self.config.output_mode == \"regression\":\n",
        "                    loss_fct = MSELoss()\n",
        "                    loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "                \n",
        "                if self.config.gradient_accumulation_steps > 1:\n",
        "                    loss = loss / self.config.gradient_accumulation_steps\n",
        "                else:\n",
        "                    loss.backward()\n",
        "                \n",
        "                tr_loss += loss.item()\n",
        "                nb_tr_examples += input_ids.size(0)\n",
        "                nb_tr_steps += 1\n",
        "                \n",
        "                if (step + 1) % self.config.gradient_accumulation_steps == 0:\n",
        "                    if self.config.fp16:\n",
        "                        lr_this_step = self.config.learning_rate * warmup_linear(\n",
        "                            global_step / self.num_train_optimization_steps, self.config.warm_up_proportion)\n",
        "                        for param_group in self.optimizer.param_groups:\n",
        "                            param_group['lr'] = lr_this_step\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    self.optimizer.step()\n",
        "                    self.scheduler.step()\n",
        "                    self.optimizer.zero_grad()\n",
        "                    global_step += 1\n",
        "            \n",
        "            # Validation\n",
        "            validation_loader = self.get_loader(validation_examples, phase='eval')\n",
        "            model.eval()\n",
        "            \n",
        "            valid_loss, valid_accuracy = 0, 0\n",
        "            nb_valid_steps, nb_valid_examples = 0, 0\n",
        "            \n",
        "            for input_ids, attention_mask, token_type_ids, label_ids, agree_ids in tqdm(validation_loader, desc=\"Validating\"):\n",
        "                input_ids = input_ids.to(self.device)\n",
        "                attention_mask = attention_mask.to(self.device)\n",
        "                token_type_ids = token_type_ids.to(self.device)\n",
        "                label_ids = label_ids.to(self.device)\n",
        "                agree_ids = agree_ids.to(self.device)\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    logits = model(input_ids, attention_mask, token_type_ids)[0]\n",
        "                    \n",
        "                    if self.config.output_mode == \"classification\":\n",
        "                        loss_fct = CrossEntropyLoss(weight=weights)\n",
        "                        tmp_valid_loss = loss_fct(logits.view(-1, self.num_labels), label_ids.view(-1))\n",
        "                    elif self.config.output_mode == \"regression\":\n",
        "                        loss_fct = MSELoss()\n",
        "                        tmp_valid_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "                    \n",
        "                    valid_loss += tmp_valid_loss.mean().item()\n",
        "                    nb_valid_steps += 1\n",
        "            \n",
        "            valid_loss = valid_loss / nb_valid_steps\n",
        "            self.validation_losses.append(valid_loss)\n",
        "            print(\"Validation losses: {}\".format(self.validation_losses))\n",
        "            \n",
        "            if valid_loss == min(self.validation_losses):\n",
        "                try:\n",
        "                    os.remove(self.config.model_dir / ('temporary' + str(best_model)))\n",
        "                except:\n",
        "                    print('No best model found')\n",
        "                torch.save({'epoch': str(epoch), 'state_dict': model.state_dict()},\n",
        "                           self.config.model_dir / ('temporary' + str(epoch)))\n",
        "                best_model = epoch\n",
        "        \n",
        "        # Save the trained model\n",
        "        checkpoint = torch.load(self.config.model_dir / ('temporary' + str(best_model)))\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model\n",
        "        output_model_file = os.path.join(self.config.model_dir, WEIGHTS_NAME)\n",
        "        torch.save(model_to_save.state_dict(), output_model_file)\n",
        "        output_config_file = os.path.join(self.config.model_dir, CONFIG_NAME)\n",
        "        with open(output_config_file, 'w') as f:\n",
        "            f.write(model_to_save.config.to_json_string())\n",
        "        os.remove(self.config.model_dir / ('temporary' + str(best_model)))\n",
        "        \n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Profiled Predict Function\n",
        "\n",
        "This function profiles the inference process for sentiment prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def profiled_predict(text, model, write_to_csv=False, path=None, use_gpu=False, gpu_name='cuda:0', batch_size=5):\n",
        "    \"\"\"\n",
        "    Predict sentiments with profiling instrumentation.\n",
        "    \n",
        "    Note: GPU-specific profiling (ProfilerActivity.CUDA) only works with NVIDIA CUDA devices.\n",
        "    For MPS (Apple Silicon), only CPU profiling is available, though actual computation runs on GPU.\n",
        "    \"\"\"\n",
        "    from nltk.tokenize import sent_tokenize\n",
        "    from finbert.utils import InputExample, convert_examples_to_features, softmax, chunks, get_device\n",
        "    from transformers import AutoTokenizer\n",
        "    \n",
        "    model.eval()\n",
        "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "    \n",
        "    # Use the device helper function for better device selection\n",
        "    if use_gpu:\n",
        "        device = get_device(no_cuda=False)\n",
        "        # If user specified a specific CUDA device, use it\n",
        "        if device.type == \"cuda\" and gpu_name.startswith(\"cuda:\"):\n",
        "            device = torch.device(gpu_name)\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    \n",
        "    print(f\"\\\\n{'='*80}\")\n",
        "    print(f\"Starting Profiled Inference\")\n",
        "    print(f\"Device: {device}\")\n",
        "    if device.type == \"mps\":\n",
        "        print(\"Note: MPS profiling shows CPU time only. Actual GPU execution time not separately tracked.\")\n",
        "    print(f\"{'='*80}\\\\n\")\n",
        "    \n",
        "    label_list = ['positive', 'negative', 'neutral']\n",
        "    label_dict = {0: 'positive', 1: 'negative', 2: 'neutral'}\n",
        "    result = pd.DataFrame(columns=['sentence', 'logit', 'prediction', 'sentiment_score'])\n",
        "    \n",
        "    # Setup profiler - CUDA profiling only works with NVIDIA GPUs, not MPS\n",
        "    activities = [ProfilerActivity.CPU]\n",
        "    if device.type == \"cuda\":\n",
        "        activities.append(ProfilerActivity.CUDA)\n",
        "    \n",
        "    with profile(\n",
        "        activities=activities,\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=False\n",
        "    ) as prof:\n",
        "        \n",
        "        with record_function(\"sentence_tokenization\"):\n",
        "            sentences = sent_tokenize(text)\n",
        "        \n",
        "        for batch in chunks(sentences, batch_size):\n",
        "            with record_function(\"create_examples\"):\n",
        "                examples = [InputExample(str(i), sentence) for i, sentence in enumerate(batch)]\n",
        "            \n",
        "            with record_function(\"convert_to_features\"):\n",
        "                features = convert_examples_to_features(examples, label_list, 64, tokenizer)\n",
        "            \n",
        "            with record_function(\"prepare_tensors\"):\n",
        "                all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long).to(device)\n",
        "                all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long).to(device)\n",
        "                all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long).to(device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                with record_function(\"model_to_device\"):\n",
        "                    model = model.to(device)\n",
        "                \n",
        "                with record_function(\"inference_forward\"):\n",
        "                    logits = model(all_input_ids, all_attention_mask, all_token_type_ids)[0]\n",
        "                \n",
        "                with record_function(\"postprocess_results\"):\n",
        "                    logits = softmax(np.array(logits.cpu()))\n",
        "                    sentiment_score = pd.Series(logits[:, 0] - logits[:, 1])\n",
        "                    predictions = np.squeeze(np.argmax(logits, axis=1))\n",
        "                    \n",
        "                    batch_result = {'sentence': batch,\n",
        "                                    'logit': list(logits),\n",
        "                                    'prediction': predictions,\n",
        "                                    'sentiment_score': sentiment_score}\n",
        "                    \n",
        "                    batch_result = pd.DataFrame(batch_result)\n",
        "                    result = pd.concat([result, batch_result], ignore_index=True)\n",
        "    \n",
        "    # Print profiler results\n",
        "    print(f\"\\\\n{'='*80}\")\n",
        "    print(\"PROFILING RESULTS - Inference\")\n",
        "    print(f\"{'='*80}\\\\n\")\n",
        "    \n",
        "    print(\"\\\\nBy CPU Time:\")\n",
        "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
        "    \n",
        "    if device.type == \"cuda\":\n",
        "        print(\"\\\\nBy CUDA Time:\")\n",
        "        print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
        "    \n",
        "    print(f\"\\\\n{'='*80}\\\\n\")\n",
        "    \n",
        "    result['prediction'] = result.prediction.apply(lambda x: label_dict[x])\n",
        "    if write_to_csv:\n",
        "        result.to_csv(path, sep=',', index=False)\n",
        "    \n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting path variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "cl_path = project_dir/'models'/'sentiment'\n",
        "cl_data_path = project_dir/'data'/'sentiment_data'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Configuring training parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Clean the cl_path\n",
        "try:\n",
        "    shutil.rmtree(cl_path) \n",
        "except:\n",
        "    pass\n",
        "\n",
        "bertmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', cache_dir=None, num_labels=3)\n",
        "\n",
        "config = Config(   data_dir=cl_data_path,\n",
        "                   bert_model=bertmodel,\n",
        "                   num_train_epochs=4,\n",
        "                   model_dir=cl_path,\n",
        "                   max_seq_length = 48,\n",
        "                   train_batch_size = 32,\n",
        "                   learning_rate = 2e-5,\n",
        "                   output_mode='classification',\n",
        "                   warm_up_proportion=0.2,\n",
        "                   local_rank=-1,\n",
        "                   discriminate=True,\n",
        "                   gradual_unfreeze=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "finbert = ProfiledFinBert(config)\n",
        "finbert.base_model = 'bert-base-uncased'\n",
        "finbert.config.discriminate=True\n",
        "finbert.config.gradual_unfreeze=True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11/22/2025 20:16:47 - INFO - finbert.finbert -   device: mps n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ]
        }
      ],
      "source": [
        "\n",
        "finbert.prepare_model(label_list=['positive','negative','neutral'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tune the model with profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the training examples\n",
        "train_data = finbert.get_data('train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = finbert.create_the_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training with Profiling\n",
        "\n",
        "This will profile the first 20 steps of the first epoch, then continue with normal training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11/22/2025 20:16:48 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:16:48 - INFO - finbert.utils -   guid: train-1\n",
            "11/22/2025 20:16:48 - INFO - finbert.utils -   tokens: [CLS] after the reporting period , bio ##tie north american licensing partner so ##max ##on pharmaceuticals announced positive results with na ##lm ##efe ##ne in a pilot phase 2 clinical trial for smoking ce ##ssa ##tion [SEP]\n",
            "11/22/2025 20:16:48 - INFO - finbert.utils -   input_ids: 101 2044 1996 7316 2558 1010 16012 9515 2167 2137 13202 4256 2061 17848 2239 24797 2623 3893 3463 2007 6583 13728 27235 2638 1999 1037 4405 4403 1016 6612 3979 2005 9422 8292 11488 3508 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:16:48 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:16:48 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:16:48 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "11/22/2025 20:16:49 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "11/22/2025 20:16:49 - INFO - finbert.finbert -     Num examples = 3488\n",
            "11/22/2025 20:16:49 - INFO - finbert.finbert -     Batch size = 32\n",
            "11/22/2025 20:16:49 - INFO - finbert.finbert -     Num steps = 48\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "Starting Profiled Training\n",
            "Device: mps\n",
            "Profiling activities: [<ProfilerActivity.CPU: 0>]\n",
            "================================================================================\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration:  18%|█▊        | 20/109 [00:07<00:34,  2.56it/s]\n",
            "Epoch:   0%|          | 0/4 [00:07<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "Profiling complete for first epoch (20 steps)\n",
            "Continuing full training without profiling...\n",
            "================================================================================\\n\n",
            "\\n================================================================================\n",
            "PROFILING RESULTS - Training\n",
            "================================================================================\\n\n",
            "\\nBy CPU Time:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                       loss_calculation         0.07%       5.979ms        38.69%        3.253s     154.928ms           0 B           0 B            21  \n",
            "                                           forward_pass         0.82%      69.062ms        37.32%        3.138s     149.445ms           0 B         -84 B            21  \n",
            "                                            aten::copy_        33.00%        2.775s        33.01%        2.776s       1.016ms           0 B           0 B          2732  \n",
            "                                               aten::to         0.03%       2.634ms        32.90%        2.767s       1.186ms       5.99 KB           0 B          2333  \n",
            "                                         aten::_to_copy         0.06%       4.803ms        32.87%        2.764s       1.625ms       5.99 KB          24 B          1701  \n",
            "                     aten::scaled_dot_product_attention         0.02%       1.279ms        11.92%        1.002s       3.978ms           0 B           0 B           252  \n",
            "               aten::_scaled_dot_product_attention_math         0.04%       3.442ms        11.90%        1.001s       3.973ms           0 B        -112 B           252  \n",
            "                               aten::cross_entropy_loss         0.01%     746.713us         8.45%     711.017ms      33.858ms           0 B           0 B            21  \n",
            "                                          aten::dropout         0.05%       4.451ms         7.98%     671.470ms     841.441us           0 B         -40 B           798  \n",
            "                                          backward_pass         7.80%     656.155ms         7.86%     660.599ms      31.457ms           0 B           0 B            21  \n",
            "                                       aten::bernoulli_         6.46%     543.462ms         7.55%     634.661ms     795.315us           0 B           0 B           798  \n",
            "                                    aten::_safe_softmax         0.03%       2.732ms         7.17%     602.655ms       2.391ms           0 B           0 B           252  \n",
            "                                              aten::all         6.74%     567.156ms         6.74%     567.156ms       2.077ms           0 B           0 B           273  \n",
            "                                         optimizer_step         0.27%      22.650ms         6.63%     557.660ms      26.555ms           8 B           0 B            21  \n",
            "                                           aten::linear         5.91%     496.788ms         5.94%     499.467ms     321.407us           0 B           0 B          1554  \n",
            "                                      aten::nll_loss_nd         0.00%     214.204us         4.71%     396.000ms      18.857ms           0 B           0 B            21  \n",
            "                                         aten::nll_loss         0.00%     320.917us         4.71%     395.786ms      18.847ms           0 B           0 B            21  \n",
            "                                 aten::nll_loss_forward         4.61%     387.848ms         4.70%     395.465ms      18.832ms           0 B           0 B            21  \n",
            "autograd::engine::evaluate_function: LinearBackward0...         0.00%     222.334us         4.14%     347.924ms      16.568ms           0 B           0 B            21  \n",
            "                                        LinearBackward0         0.00%     192.834us         4.13%     347.702ms      16.557ms           0 B           0 B            21  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 8.410s\n",
            "\n",
            "\\n================================================================================\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:23<00:00,  4.73it/s]\n",
            "11/22/2025 20:17:24 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:17:24 - INFO - finbert.utils -   guid: validation-1\n",
            "11/22/2025 20:17:24 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "11/22/2025 20:17:24 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:17:24 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:17:24 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:17:24 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "11/22/2025 20:17:24 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "11/22/2025 20:17:24 - INFO - finbert.finbert -     Num examples = 388\n",
            "11/22/2025 20:17:24 - INFO - finbert.finbert -     Batch size = 32\n",
            "11/22/2025 20:17:24 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  6.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.8772950309973496]\n",
            "No best model found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:37<00:00,  2.94it/s]\n",
            "11/22/2025 20:18:04 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:18:04 - INFO - finbert.utils -   guid: validation-1\n",
            "11/22/2025 20:18:04 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "11/22/2025 20:18:04 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:18:04 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:18:04 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:18:04 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "11/22/2025 20:18:04 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "11/22/2025 20:18:04 - INFO - finbert.finbert -     Num examples = 388\n",
            "11/22/2025 20:18:04 - INFO - finbert.finbert -     Batch size = 32\n",
            "11/22/2025 20:18:04 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  8.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.8772950309973496, 0.6009280452361474]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:44<00:00,  2.45it/s]\n",
            "11/22/2025 20:18:51 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:18:51 - INFO - finbert.utils -   guid: validation-1\n",
            "11/22/2025 20:18:51 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "11/22/2025 20:18:51 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:18:51 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:18:51 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:18:51 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "11/22/2025 20:18:51 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "11/22/2025 20:18:51 - INFO - finbert.finbert -     Num examples = 388\n",
            "11/22/2025 20:18:51 - INFO - finbert.finbert -     Batch size = 32\n",
            "11/22/2025 20:18:51 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  8.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.8772950309973496, 0.6009280452361474, 0.5078935806567852]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 109/109 [00:56<00:00,  1.94it/s]\n",
            "11/22/2025 20:19:50 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:19:50 - INFO - finbert.utils -   guid: validation-1\n",
            "11/22/2025 20:19:50 - INFO - finbert.utils -   tokens: [CLS] our in - depth expertise extends to the fields of energy , industry , urban & mobility and water & environment [SEP]\n",
            "11/22/2025 20:19:50 - INFO - finbert.utils -   input_ids: 101 2256 1999 1011 5995 11532 8908 2000 1996 4249 1997 2943 1010 3068 1010 3923 1004 12969 1998 2300 1004 4044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:50 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:50 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:50 - INFO - finbert.utils -   label: neutral (id = 2)\n",
            "11/22/2025 20:19:50 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "11/22/2025 20:19:50 - INFO - finbert.finbert -     Num examples = 388\n",
            "11/22/2025 20:19:50 - INFO - finbert.finbert -     Batch size = 32\n",
            "11/22/2025 20:19:50 - INFO - finbert.finbert -     Num steps = 48\n",
            "Validating: 100%|██████████| 13/13 [00:01<00:00,  9.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation losses: [0.8772950309973496, 0.6009280452361474, 0.5078935806567852, 0.46449002852806676]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 4/4 [02:51<00:00, 42.87s/it]\n"
          ]
        }
      ],
      "source": [
        "trained_model = finbert.train(train_examples = train_data, model = model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = finbert.get_data('test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11/22/2025 20:19:54 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:19:54 - INFO - finbert.utils -   guid: test-1\n",
            "11/22/2025 20:19:54 - INFO - finbert.utils -   tokens: [CLS] the bristol port company has sealed a one million pound contract with cooper specialised handling to supply it with four 45 - ton ##ne , custom ##ised reach stack ##ers from ko ##ne ##cr ##ane ##s [SEP]\n",
            "11/22/2025 20:19:54 - INFO - finbert.utils -   input_ids: 101 1996 7067 3417 2194 2038 10203 1037 2028 2454 9044 3206 2007 6201 17009 8304 2000 4425 2009 2007 2176 3429 1011 10228 2638 1010 7661 5084 3362 9991 2545 2013 12849 2638 26775 7231 2015 102 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:54 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:54 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:54 - INFO - finbert.utils -   label: positive (id = 0)\n",
            "11/22/2025 20:19:54 - INFO - finbert.finbert -   ***** Loading data *****\n",
            "11/22/2025 20:19:54 - INFO - finbert.finbert -     Num examples = 970\n",
            "11/22/2025 20:19:54 - INFO - finbert.finbert -     Batch size = 32\n",
            "11/22/2025 20:19:54 - INFO - finbert.finbert -     Num steps = 120\n",
            "11/22/2025 20:19:54 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
            "11/22/2025 20:19:54 - INFO - finbert.finbert -     Num examples = 970\n",
            "11/22/2025 20:19:54 - INFO - finbert.finbert -     Batch size = 32\n",
            "Testing: 100%|██████████| 31/31 [00:04<00:00,  6.90it/s]\n"
          ]
        }
      ],
      "source": [
        "results = finbert.evaluate(examples=test_data, model=trained_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare the classification report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def report(df, cols=['label','prediction','logits']):\n",
        "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
        "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
        "    print(\"Loss:{0:.2f}\".format(loss))\n",
        "    print(\"Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
        "    print(\"\\\\nClassification Report:\")\n",
        "    print(classification_report(df[cols[0]], df[cols[1]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:0.51\n",
            "Accuracy:0.77\n",
            "\\nClassification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.76      0.71       267\n",
            "           1       0.62      0.91      0.74       128\n",
            "           2       0.90      0.74      0.81       575\n",
            "\n",
            "    accuracy                           0.77       970\n",
            "   macro avg       0.73      0.81      0.75       970\n",
            "weighted avg       0.80      0.77      0.77       970\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/w6/ggz_63f15v74qh97559bpz2r0000gn/T/ipykernel_57363/562382605.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)\n",
            "  loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n"
          ]
        }
      ],
      "source": [
        "report(results,cols=['labels','prediction','predictions'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get predictions with profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"Later that day Apple said it was revising down its earnings expectations in \\\n",
        "the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China. \\\n",
        "The news rapidly infected financial markets. Apple's share price fell by around 7% in after-hours \\\n",
        "trading and the decline was extended to more than 10% when the market opened. The dollar fell \\\n",
        "by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering \\\n",
        "some ground. Asian stockmarkets closed down on January 3rd and European ones opened lower. \\\n",
        "Yields on government bonds fell as investors fled to the traditional haven in a market storm.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "cl_path = project_dir/'models'/'sentiment'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(cl_path, cache_dir=None, num_labels=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/taimurshaikh/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11/22/2025 20:19:59 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   guid: 0\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   tokens: [CLS] later that day apple said it was rev ##ising down its earnings expectations in the fourth quarter of 2018 , largely because of lower sales and signs of economic weakness in china . [SEP]\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   input_ids: 101 2101 2008 2154 6207 2056 2009 2001 7065 9355 2091 2049 16565 10908 1999 1996 2959 4284 1997 2760 1010 4321 2138 1997 2896 4341 1998 5751 1997 3171 11251 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "Starting Profiled Inference\n",
            "Device: cpu\n",
            "================================================================================\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/w6/ggz_63f15v74qh97559bpz2r0000gn/T/ipykernel_57363/3181103054.py:65: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
            "  logits = softmax(np.array(logits.cpu()))\n",
            "/var/folders/w6/ggz_63f15v74qh97559bpz2r0000gn/T/ipykernel_57363/3181103054.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, batch_result], ignore_index=True)\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   guid: 0\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   tokens: [CLS] yields on government bonds fell as investors fled to the traditional haven in a market storm . [SEP]\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   input_ids: 101 16189 2006 2231 9547 3062 2004 9387 6783 2000 1996 3151 4033 1999 1037 3006 4040 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:19:59 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "PROFILING RESULTS - Inference\n",
            "================================================================================\\n\n",
            "\\nBy CPU Time:\n",
            "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    inference_forward        13.80%      37.599ms        87.63%     238.733ms     119.367ms          72 B    -248.22 MB             2  \n",
            "                                         aten::linear         0.78%       2.130ms        58.05%     158.139ms       1.069ms     121.52 MB           0 B           148  \n",
            "                                          aten::addmm        52.06%     141.819ms        56.46%     153.818ms       1.039ms     121.52 MB     121.52 MB           148  \n",
            "                                sentence_tokenization         6.65%      18.106ms         6.65%      18.106ms      18.106ms           0 B           0 B             1  \n",
            "                                           aten::gelu         5.37%      14.624ms         5.37%      14.624ms     609.334us      54.00 MB      54.00 MB            24  \n",
            "                                          aten::copy_         4.40%      11.976ms         4.40%      11.976ms      77.765us           0 B           0 B           154  \n",
            "                   aten::scaled_dot_product_attention         0.33%     908.710us         4.26%      11.614ms     483.931us      13.50 MB    -216.00 KB            24  \n",
            "    aten::_scaled_dot_product_flash_attention_for_cpu         3.66%       9.968ms         3.93%      10.706ms     446.068us      13.71 MB      -2.29 MB            24  \n",
            "                                  convert_to_features         2.26%       6.146ms         2.26%       6.146ms       3.073ms           0 B           0 B             2  \n",
            "                                     aten::layer_norm         0.10%     266.963us         2.24%       6.099ms     121.975us      28.12 MB     -75.00 KB            50  \n",
            "                              aten::native_layer_norm         1.99%       5.417ms         2.14%       5.832ms     116.636us      28.20 MB       2.00 KB            50  \n",
            "                                      model_to_device         1.51%       4.100ms         1.74%       4.728ms       2.364ms           0 B           0 B             2  \n",
            "                                            aten::add         1.40%       3.811ms         1.40%       3.811ms      76.214us      28.12 MB      28.12 MB            50  \n",
            "                                      aten::embedding         0.02%      58.917us         1.09%       2.973ms     495.507us       2.62 MB           0 B             6  \n",
            "                                   aten::index_select         1.04%       2.840ms         1.06%       2.885ms     480.875us       2.62 MB       2.62 MB             6  \n",
            "                                  postprocess_results         0.93%       2.532ms         0.94%       2.549ms       1.275ms         -72 B         -72 B             2  \n",
            "                                      prepare_tensors         0.76%       2.058ms         0.78%       2.130ms       1.065ms       1.50 KB      -7.50 KB             2  \n",
            "                                      aten::transpose         0.32%     868.161us         0.50%       1.354ms       3.489us           0 B           0 B           388  \n",
            "                                           aten::view         0.46%       1.251ms         0.46%       1.251ms       2.406us           0 B           0 B           520  \n",
            "                                              aten::t         0.23%     632.119us         0.41%       1.120ms       7.565us           0 B           0 B           148  \n",
            "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 272.435ms\n",
            "\n",
            "\\n================================================================================\\n\n"
          ]
        }
      ],
      "source": [
        "result = profiled_predict(text, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>logit</th>\n",
              "      <th>prediction</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>textblob_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Later that day Apple said it was revising down its earnings expectations in the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China.</td>\n",
              "      <td>[0.14201558, 0.83104205, 0.026942372]</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.689026</td>\n",
              "      <td>0.051746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The news rapidly infected financial markets.</td>\n",
              "      <td>[0.0788608, 0.59356976, 0.32756948]</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.514709</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apple's share price fell by around 7% in after-hours trading and the decline was extended to more than 10% when the market opened.</td>\n",
              "      <td>[0.056227226, 0.90114564, 0.042627137]</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.844918</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The dollar fell by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering some ground.</td>\n",
              "      <td>[0.12553856, 0.8490222, 0.025439167]</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.723484</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Asian stockmarkets closed down on January 3rd and European ones opened lower.</td>\n",
              "      <td>[0.07658135, 0.7828065, 0.14061213]</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.706225</td>\n",
              "      <td>-0.051111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                          sentence  \\\n",
              "0  Later that day Apple said it was revising down its earnings expectations in the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China.   \n",
              "1                                                                                                                                     The news rapidly infected financial markets.   \n",
              "2                                               Apple's share price fell by around 7% in after-hours trading and the decline was extended to more than 10% when the market opened.   \n",
              "3                                                    The dollar fell by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering some ground.   \n",
              "4                                                                                                    Asian stockmarkets closed down on January 3rd and European ones opened lower.   \n",
              "\n",
              "                                    logit prediction  sentiment_score  \\\n",
              "0   [0.14201558, 0.83104205, 0.026942372]   negative        -0.689026   \n",
              "1     [0.0788608, 0.59356976, 0.32756948]   negative        -0.514709   \n",
              "2  [0.056227226, 0.90114564, 0.042627137]   negative        -0.844918   \n",
              "3    [0.12553856, 0.8490222, 0.025439167]   negative        -0.723484   \n",
              "4     [0.07658135, 0.7828065, 0.14061213]   negative        -0.706225   \n",
              "\n",
              "   textblob_prediction  \n",
              "0             0.051746  \n",
              "1             0.000000  \n",
              "2             0.500000  \n",
              "3             0.000000  \n",
              "4            -0.051111  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "blob = TextBlob(text)\n",
        "result['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]\n",
        "result.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average sentiment is -0.71.\n"
          ]
        }
      ],
      "source": [
        "print(f'Average sentiment is %.2f.' % (result.sentiment_score.mean()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Second example with profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "text2 = \"Shares in the spin-off of South African e-commerce group Naspers surged more than 25% \\\n",
        "in the first minutes of their market debut in Amsterdam on Wednesday. Bob van Dijk, CEO of \\\n",
        "Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the \\\n",
        "Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019. REUTERS/Piroschka van de Wouw \\\n",
        "Prosus comprises Naspers' global empire of consumer internet assets, with the jewel in the crown a \\\n",
        "31% stake in Chinese tech titan Tencent. There is 'way more demand than is even available, so that's \\\n",
        "good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg. 'It's going to be an interesting \\\n",
        "hour of trade after opening this morning.' Euronext had given an indicative price of 58.70 euros \\\n",
        "per share for Prosus, implying a market value of 95.3 billion euros ($105 billion). The shares \\\n",
        "jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11/22/2025 20:20:00 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   guid: 0\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   tokens: [CLS] shares in the spin - off of south african e - commerce group nas ##pers surged more than 25 % in the first minutes of their market debut in amsterdam on wednesday . [SEP]\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   input_ids: 101 6661 1999 1996 6714 1011 2125 1997 2148 3060 1041 1011 6236 2177 17235 7347 18852 2062 2084 2423 1003 1999 1996 2034 2781 1997 2037 3006 2834 1999 7598 2006 9317 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "Starting Profiled Inference\n",
            "Device: cpu\n",
            "================================================================================\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/w6/ggz_63f15v74qh97559bpz2r0000gn/T/ipykernel_57363/3181103054.py:65: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
            "  logits = softmax(np.array(logits.cpu()))\n",
            "/var/folders/w6/ggz_63f15v74qh97559bpz2r0000gn/T/ipykernel_57363/3181103054.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, batch_result], ignore_index=True)\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   *** Example ***\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   guid: 0\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   tokens: [CLS] euro ##ne ##xt had given an indicative price of 58 . 70 euros per share for pro ##sus , implying a market value of 95 . 3 billion euros ( $ 105 billion ) . [SEP]\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   input_ids: 101 9944 2638 18413 2018 2445 2019 24668 3976 1997 5388 1012 3963 19329 2566 3745 2005 4013 13203 1010 20242 1037 3006 3643 1997 5345 1012 1017 4551 19329 1006 1002 8746 4551 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/22/2025 20:20:00 - INFO - finbert.utils -   label: None (id = 9090)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n================================================================================\n",
            "PROFILING RESULTS - Inference\n",
            "================================================================================\\n\n",
            "\\nBy CPU Time:\n",
            "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                    inference_forward        19.26%      39.431ms        93.35%     191.154ms      95.577ms          84 B    -289.52 MB             2  \n",
            "                                         aten::linear         0.84%       1.722ms        56.77%     116.238ms     785.391us     141.77 MB           0 B           148  \n",
            "                                          aten::addmm        49.25%     100.856ms        54.92%     112.465ms     759.897us     141.77 MB     141.77 MB           148  \n",
            "                                           aten::gelu         7.48%      15.320ms         7.48%      15.320ms     638.317us      63.00 MB      63.00 MB            24  \n",
            "                                          aten::copy_         5.43%      11.126ms         5.43%      11.126ms      72.246us           0 B           0 B           154  \n",
            "                   aten::scaled_dot_product_attention         0.11%     225.879us         4.13%       8.463ms     352.639us      15.75 MB    -252.00 KB            24  \n",
            "    aten::_scaled_dot_product_flash_attention_for_cpu         3.71%       7.591ms         4.02%       8.237ms     343.227us      16.00 MB      -2.29 MB            24  \n",
            "                                  convert_to_features         2.80%       5.741ms         2.80%       5.741ms       2.870ms           0 B           0 B             2  \n",
            "                                      model_to_device         2.62%       5.368ms         2.80%       5.738ms       2.869ms           0 B           0 B             2  \n",
            "                                     aten::layer_norm         0.14%     287.163us         2.56%       5.237ms     104.749us      32.81 MB     -86.50 KB            50  \n",
            "                              aten::native_layer_norm         2.20%       4.496ms         2.42%       4.950ms      99.006us      32.90 MB         512 B            50  \n",
            "                                            aten::add         1.92%       3.933ms         1.92%       3.933ms      78.666us      32.81 MB      32.81 MB            50  \n",
            "                                  postprocess_results         0.75%       1.538ms         0.76%       1.551ms     775.562us         -84 B         -84 B             2  \n",
            "                                      aten::embedding         0.02%      48.830us         0.69%       1.420ms     236.729us       3.00 MB           0 B             6  \n",
            "                                           aten::view         0.66%       1.348ms         0.66%       1.348ms       2.592us           0 B           0 B           520  \n",
            "                                   aten::index_select         0.64%       1.302ms         0.65%       1.340ms     223.375us       3.00 MB       3.00 MB             6  \n",
            "                                      aten::transpose         0.38%     785.569us         0.60%       1.233ms       3.178us           0 B           0 B           388  \n",
            "                                              aten::t         0.16%     334.932us         0.41%     846.262us       5.718us           0 B           0 B           148  \n",
            "                                        aten::reshape         0.12%     240.175us         0.29%     589.008us       3.385us           0 B           0 B           174  \n",
            "                                     aten::as_strided         0.28%     563.267us         0.28%     563.267us       0.964us           0 B           0 B           584  \n",
            "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 204.768ms\n",
            "\n",
            "\\n================================================================================\\n\n"
          ]
        }
      ],
      "source": [
        "result2 = profiled_predict(text2, model)\n",
        "blob = TextBlob(text2)\n",
        "result2['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>logit</th>\n",
              "      <th>prediction</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>textblob_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Shares in the spin-off of South African e-commerce group Naspers surged more than 25% in the first minutes of their market debut in Amsterdam on Wednesday.</td>\n",
              "      <td>[0.7369177, 0.06687665, 0.19620562]</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.670041</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bob van Dijk, CEO of Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019.</td>\n",
              "      <td>[0.18849334, 0.043508735, 0.7679979]</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.144985</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>REUTERS/Piroschka van de Wouw Prosus comprises Naspers' global empire of consumer internet assets, with the jewel in the crown a 31% stake in Chinese tech titan Tencent.</td>\n",
              "      <td>[0.26907253, 0.02341426, 0.70751315]</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.245658</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>There is 'way more demand than is even available, so that's good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg.</td>\n",
              "      <td>[0.73105943, 0.06360316, 0.2053374]</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.667456</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'It's going to be an interesting hour of trade after opening this morning.'</td>\n",
              "      <td>[0.58056855, 0.10513434, 0.31429714]</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.475434</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Euronext had given an indicative price of 58.70 euros per share for Prosus, implying a market value of 95.3 billion euros ($105 billion).</td>\n",
              "      <td>[0.231448, 0.05059284, 0.7179592]</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.180855</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The shares jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.</td>\n",
              "      <td>[0.33516562, 0.042202037, 0.6226323]</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.292964</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                    sentence  \\\n",
              "0                                Shares in the spin-off of South African e-commerce group Naspers surged more than 25% in the first minutes of their market debut in Amsterdam on Wednesday.   \n",
              "1  Bob van Dijk, CEO of Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019.   \n",
              "2                  REUTERS/Piroschka van de Wouw Prosus comprises Naspers' global empire of consumer internet assets, with the jewel in the crown a 31% stake in Chinese tech titan Tencent.   \n",
              "3                                                                There is 'way more demand than is even available, so that's good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg.   \n",
              "4                                                                                                                'It's going to be an interesting hour of trade after opening this morning.'   \n",
              "5                                                  Euronext had given an indicative price of 58.70 euros per share for Prosus, implying a market value of 95.3 billion euros ($105 billion).   \n",
              "6                                                                                                         The shares jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.   \n",
              "\n",
              "                                  logit prediction  sentiment_score  \\\n",
              "0   [0.7369177, 0.06687665, 0.19620562]   positive         0.670041   \n",
              "1  [0.18849334, 0.043508735, 0.7679979]    neutral         0.144985   \n",
              "2  [0.26907253, 0.02341426, 0.70751315]    neutral         0.245658   \n",
              "3   [0.73105943, 0.06360316, 0.2053374]   positive         0.667456   \n",
              "4  [0.58056855, 0.10513434, 0.31429714]   positive         0.475434   \n",
              "5     [0.231448, 0.05059284, 0.7179592]    neutral         0.180855   \n",
              "6  [0.33516562, 0.042202037, 0.6226323]    neutral         0.292964   \n",
              "\n",
              "   textblob_prediction  \n",
              "0             0.250000  \n",
              "1             0.000000  \n",
              "2             0.000000  \n",
              "3             0.533333  \n",
              "4             0.500000  \n",
              "5             0.000000  \n",
              "6             0.000000  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average sentiment is 0.38.\n"
          ]
        }
      ],
      "source": [
        "print(f'Average sentiment is %.2f.' % (result2.sentiment_score.mean()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides baseline profiling data for:\n",
        "1. **Training operations**: Data loading, forward pass, loss calculation, backward pass, optimizer step\n",
        "2. **Inference operations**: Tokenization, feature conversion, model forward pass, postprocessing\n",
        "\n",
        "The profiling output shows CPU time (and CUDA time if available) for each operation, which can be used to identify optimization opportunities.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
